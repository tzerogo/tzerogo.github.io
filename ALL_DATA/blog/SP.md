
# 复习概率论

## 随机试验

随机试验：1. 可重复；2. 结果不止一个；3. 每次试验前不能确定哪个结果发生F(X)=\int_{-\infty} ^x f_X(t) dt。

样本空间 $\Omega$：所有可能结果（基本事件）的集合。

事件域 $\mathcal{F}$ ：$\Omega$ 的所有子集，并且是可以计算概率的所组成的集合族。

随机事件 $A$ ：样本空间 $\Omega$ 的子集。

随机事件之间的运算（和、积、差）和关系（包含、相等、互斥、对立）

运算性质（吸收律、交换律、结合律、分配律、对偶律/德摩根定律）

- 独立：$P(AB)=P(A)P(B)$
- 互斥：$A \cap B = \emptyset$
- 不相关：不线性相关

- 互斥=不相容
- 两两独立（任意两个事件都是相互独立的）
- 相互独立（任意一个事件与任意其他事件的任意组合都是独立的）
- 对立是互斥的子集
- 互相独立与互斥相矛盾（除非至少一个概率为0）

## 概率

| 序号| 性质 | 公式表达 | 描述的本质 |
|-|-|-|-|
| P1| 非负性 | \ $P(A) \ge 0$ | 任何事件的概率都是非负的。|
| P2| 规范性| $P(\Omega) = 1$| 必然事件（样本空间本身）的概率是 1。|
| P3| 可列可加性| 若 $A_i$ 互不相容，则 $P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)$| 互不相容的可数个事件的并集概率等于它们概率的和。|

||Ω|假设|
|-|-|-|
|古典概率 |有限集 |等可能性|
|几何概率 |无限集 |均匀性|

- 条件概率：本质上缩小样本空间 

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

- 乘法公式 

$$P(A \cap B) = P(B) P(A|B)$$

- 全概率公式：$B_k$ 是$\Omega$ 的完备事件组（它们互斥且并集为 $\Omega$）

$$P(A) = \sum_{i=1}^{n} P(A|B_i) P(B_i)$$

- 贝叶斯公式

$$P(B_k|A) = \frac{P(A|B_k) P(B_k)}{P(A)} = \frac{P(A|B_k) P(B_k)}{\sum_{i=1}^{n} P(A|B_i) P(B_i)}$$

理解：等号左边代表的是后验概率，也就是 $B_k$ 这一随机变量在 $A$ 发生的条件下的新概率。等号右边的 $B_k$ 则代表了其本身在没有任何条件下发生的概率，也就是先验概率。

可以这样理解，如何从先验概率得到后验概率呢？显而易见的就是决定于现在多出来的这个条件，因此等号右边剩下的，也就是调节因子.代表了$A$的这个条件对于$B_k$的影响（放大或者缩小），也就等于

## 随机变量 

### 随机变量 RV

随机变量 $X$ 本质是一个函数，$X: \Omega \to \mathbb{R}$  

定义域：样本空间 $\Omega$

值域：实数集 $\mathbb{R}$

- 就是把样本空间的基本事件按照某种自己定义的方式对应成数字。当定义为对应的利润的数值的时候，期望之类就更有含义。本质目的是实现量化，使得概率论能够融入现代数学体系。

- 随机变量的取值 $X = x$ 就是指其值域的取值，也就是用随机变量的取值这一数字替代了对于样本空间的基本事件的描述。注意不同的基本事件可以对应一个具体数值。而这个数值只是描述样本的选取而与对应的概率 $P(X=x)$ 无关。


### 分布函数 CDF

$$F_X(x) = P(X \le x)$$

输入：实数 $x \in \mathbb{R}$（随机变量 $X$ 可能取到的任何值）。

输出：概率 $P(X \le x)$（一个介于 0 到 1 之间的数值）。

- 本质上也是一个函数，是对随机变量的描述，把随机变量同概率联系起来。

- 具体为什么要使用这种累积的描述方式，是因为看起来更直观的概率函数 $P(X=x)$ 在连续型变量中难以描述，而分布函数可以统一完整地描述所有类型的随机变量。同时其每个区间的 **前后概率差** 就是直观的 对应概率（$P(a < X \le b) = F_X(b) - F_X(a)$）。并且还能提供全局的视野。


| 性质名称    | 公式表达                                                                                                | 描述的本质                             | 
| ------- | --------------------------------------------------------------------------------------------------- | --------------------------------- |
| 规范性/上下界 | $0 \le F_X(x) \le 1$                                                                                | 任何累积概率的值都必须介于 0 到 1 之间。           |  
| 渐进性（极限） | (i) $\lim_{x \to -\infty} F_X(x) = 0$ (ii) $\lim_{x \to +\infty} F_X(x) = 1$                        | 保证 $X$ 作为一个随机变量，其概率在整个实数轴上是完整分配的。 | 
| 单调不减性   | 若 $x_1 < x_2$，则 $F_X(x_1) \le F_X(x_2)$                                                             | 随着阈值 $x$ 增大，累积的概率只能增加或保持不变，不可能减少。 | 
| 右连续性    | $\lim_{x \to x_0^+} F_X(x) = F_X(x_0)$ （即 $\lim_{\epsilon \to 0^+} F_X(x_0 + \epsilon) = F_X(x_0)$） | 保证了概率在数值上是一致的，尤其是对于离散型随机变量的跳跃点。   |  



- $F_X(x) = P(X \le x)$ 正是这个“ $\le$”（小于或等于）决定了必须选择右连续性。右连续性保证了 $F_X(x_0)$ 必须包含 $X$ 恰好取到 $x_0$ 这个点的概率 $P(X=x_0)$。


### 常见分布

离散型：

| 分布名称                     | 概率质量函数（PMF）                                                     | 参数                             | 期望值            | 方差                              | 应用场景            |
| ------------------------ | --------------------------------------------------------------- | ------------------------------ | -------------- | ------------------------------- | --------------- |
| 伯努利分布（Bernoulli）         | $P(X = k) = p^k (1-p)^{1-k}$                                    | $p$（成功概率）                      | $p$            | $p(1-p)$                        | 试验只有两种结果（成功或失败） |
| 二项分布（Binomial）           | $P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}$                       | $n$（试验次数），$p$（成功概率）            | $np$           | $np(1-p)$                       | 固定次数的独立伯努利试验    |
| 泊松分布（Poisson）            | $P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}$                  | $\lambda$（平均发生率）               | $\lambda$      | $\lambda$                       | 稀有事件的发生次数       |
| 几何分布（Geometric）          | $P(X = k) = (1-p)^{k-1} p$                                      | $p$（成功概率）                      | $\frac{1}{p}$  | $\frac{1-p}{p^2}$               | 第一次成功所需的试验次数    |
| 负二项分布（Negative Binomial） | $P(X = k) = \binom{k+r-1}{k} p^r (1-p)^k$                       | $r$（成功次数），$p$（成功概率）            | $\frac{r}{p}$  | $\frac{r(1-p)}{p^2}$            | 达到固定成功次数所需的试验次数 |
| 超几何分布（Hypergeometric）    | $P(X = k) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}}$ | $N$（总体大小），$K$（成功状态数），$n$（样本大小） | $\frac{nK}{N}$ | $\frac{nK(N-K)(N-n)}{N^2(N-1)}$ | 不放回抽样           |


独立重复试验：试验是相互独立的，并且在相同条件下重复进行。

伯努利试验：独立重复且每次试验只有两个结果（成功/失败），成功概率 $p$ 固定。

伯努利分布->二项分布（多次伯努利试验）->泊松分布（n趋于无穷p趋于0）

伯努利分布->几何分布（第一次成功会在第几次试验）

二项分布->超几何分布（每次试验不独立，当$N$趋于无穷时近似二项）


连续型：


| 分布名称              | 概率密度函数（PDF）                                                            | 参数                          | 期望值                           | 方差                                                     | 应用场景            |
| ----------------- | ---------------------------------------------------------------------- | --------------------------- | ----------------------------- | ------------------------------------------------------ | --------------- |
| 均匀分布（Uniform）     | $f(x) = \frac{1}{b-a}$                                                 | $a$（下限），$b$（上限）             | $\frac{a+b}{2}$               | $\frac{(b-a)^2}{12}$                                   | 随机变量在区间内均匀分布    |
| 正态分布（Normal）      | $f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ | $\mu$（均值），$\sigma$（标准差）     | $\mu$                         | $\sigma^2$                                             | 自然现象和社会科学中的许多变量 |
| 指数分布（Exponential） | $f(x) = \lambda e^{-\lambda x}$                                        | $\lambda$（率参数）              | $\frac{1}{\lambda}$           | $\frac{1}{\lambda^2}$                                  | 事件之间的时间间隔       |
| 伽马分布（Gamma）       | $f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}$ | $\alpha$（形状参数），$\beta$（率参数） | $\frac{\alpha}{\beta}$        | $\frac{\alpha}{\beta^2}$                               | 事件发生的时间间隔总和     |
| 贝塔分布（Beta）        | $f(x) = \frac{x^{\alpha-1} (1-x)^{\beta-1}}{B(\alpha,\beta)}$          | $\alpha$，$\beta$（形状参数）      | $\frac{\alpha}{\alpha+\beta}$ | $\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$ | 比例或概率的建模        |
| 卡方分布（Chi-squared） | $f(x) = \frac{1}{2^{k/2} \Gamma(k/2)} x^{k/2-1} e^{-x/2}$              | $k$（自由度）                    | $k$                           | $2k$                                                   | 独立标准正态变量的平方和    |


概率密度函数（PDF）：$F(x)=\int_{-\infty} ^x f_X(t) dt$


## 多维随机变量

引入多维的随机变量是概率论从研究个体随机性升级到研究系统随机性（变量间的相互作用）的关键步骤。同两个随机变量区别的核心价值在于提供了描述和量化变量间**相互关系**的数学框架。

### 联合分布函数

$$F_{X, Y}(x, y) = P(X \le x, Y \le y)$$

单变量的分布函数描述的是，实数轴 $\mathbb{R}$ 上，点 $X$ 落在区间 $(-\infty, x]$ 内的概率。

多变量联合分布函数描述的则是，二维平面 $\mathbb{R}^2$ 上，点 $(X, Y)$ 落在左下方无限矩形区域 $\{(u, v) \mid u \le x, v \le y\}$ 内的概率。

- 对于某一个区域范围对应的概率（$P(a < X \le b, c < Y \le d)$）类似于单变量情况。在二维情况下就是对应该范围的矩形区域，但要注意对应的概率值不是面积的大小，而是该区域中所有点概率的和（离散）/该区域内概率密度函数的二重积分（连续）。

$$P(a < X \le b, c < Y \le d) = F_{X, Y}(b, d) - F_{X, Y}(a, d) - F_{X, Y}(b, c) + F_{X, Y}(a, c)$$



| 性质名称              | 公式表达                                                                                                                                                        | 描述的本质                            |
| ----------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- |
| 规范性/上下界           | $0 \le F_{X, Y}(x, y) \le 1$                                                                                                                                | 任何联合累积概率的值都必须介于 0 到 1 之间。        |
| 渐进性（极限）(i) 左下角极限  | $\lim_{x \to -\infty \text{ 或 } y \to -\infty} F_{X, Y}(x, y) = 0$                                                                                          | 只要 $X$ 或 $Y$ 中任一个趋于负无穷，联合概率就为 0。 |
| 渐进性（极限）(ii) 右上角极限 | $\lim_{x \to +\infty, y \to +\infty} F_{X, Y}(x, y) = 1$                                                                                                    | 当 $X$ 和 $Y$ 同时趋于正无穷时，联合概率为 1。    |
| 单调不减性             | 若 $x_1 < x_2$，则 $F_{X, Y}(x_1, y) \le F_{X, Y}(x_2, y)$；若 $y_1 < y_2$，则 $F_{X, Y}(x, y_1) \le F_{X, Y}(x, y_2)$                                             | 关于 $x$ 和 $y$ 两个变量都是单调不减的。        |
| 右连续性              | $\lim_{x \to x_0^+, y \to y_0^+} F_{X, Y}(x, y) = F_{X, Y}(x_0, y_0)$                                                                                       | 保证了在二维空间中，CDF 在边界点处对两个变量都是右连续的。  |
| 矩形非负性         | 对任意 $x_1 < x_2, y_1 < y_2$： $P(x_1 < X \le x_2, y_1 < Y \le y_2) = F_{X, Y}(x_2, y_2) - F_{X, Y}(x_1, y_2) - F_{X, Y}(x_2, y_1) + F_{X, Y}(x_1, y_1) \ge 0$ | 保证二维平面上任何矩形区域的概率测度都是非负的。         |



离散型随机变量：联合分布律

连续型随机变量：联合概率密度 $F(x,y)= \iint_D f(\mathbf{u,v}) d\mathbf{u} d\mathbf{v}$

- 联合分布律和联合概率密度的同等级的对偶概念，不同于分布函数是累积值，这两者代表的是特定随机变量取值所对应的概率。

### 边缘分布函数

联合分布函数 $F_{X, Y}(x, y)$ 包含了所有关于 $X$ 和 $Y$ 的概率信息，因此单变量的分布函数 $F_X(x)$ 和 $F_Y(y)$ 都可以从 $F_{X, Y}(x, y)$ 中推导出来。


对于二维随机变量$(X,Y)$，其分布函数是$F(x,y)$，其关于$X$的边缘分布函数即为：

$$F_X(x)=F(x,+\infty)=P(X\le x,Y\le +\infty)$$

针对离散型随机变量，边缘分布律就是把对应$x_i$的，包括所有对应所有$y_j$点，点概率进行求和$p_{i·}=\sum_{j}p_{ij}$

针对连续型随机变量，边缘概率密度就是把联合密度函数在$y$维度上求积分，即$f_X(x)=\int_{-\infty}^{+\infty}f(x,y)dy$

- 

### 条件分布




- 边缘分布是特殊的条件分布












<!-- ## 补充


| 原点矩      | 含义        | 中心矩               | 含义                  |
| -------- | --------      | -----------------  | -------------         |
| $E[X]$   | 数学期望（均值） | $E[(X - E[X])]$   | 一阶中心矩（为0）        |
| $E[X^2]$ | 二阶原点矩     | $E[(X - E[X])^2]$  | 方差（衡量数据的离散程度） |
| $E[X^3]$ | 三阶原点矩     | $E[(X - E[X])^3]$  | 偏度（衡量数据的对称性）  |
| $E[X^4]$ | 四阶原点矩     | $E[(X - E[X])^4]$  | 峰度（衡量数据的尖峭程度） | -->


